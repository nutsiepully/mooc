posts = read.csv("~/work//code/courses//mooc/fsf-coursera/converted.csv")
posts_text = posts["post_text"]
posts_text[1:5]
posts_text[1:5,]
posts_text <- subset(posts_text, post_text != "");
nrow(posts_text)
posts_dtm <- DocumentTermMatrix(posts_text, control = list(weighting =
function(x)
weightTf(x), removePunctuation = TRUE,
stopwords = TRUE))
library("tm")
library("topicmodels")
posts_dtm <- DocumentTermMatrix(posts_text, control = list(weighting =
function(x)
weightTf(x), removePunctuation = TRUE,
stopwords = TRUE))
posts_corpus = Corpus(DataframeSource(posts_text))
posts_dtm <- DocumentTermMatrix(posts_corpus, control = list(weighting =
function(x)
weightTf(x), removePunctuation = TRUE,
stopwords = TRUE))
training7 <- LDA(dtm, k = 7, control = list(seed = SEED))
SEED <- 1212121
training7 <- LDA(posts_dtm, k = 7, control = list(seed = SEED))
row_sub = apply(dd, 1, function(row) all(row !=0 ))
row_sub = apply(posts_dtm, 1, function(row) all(row !=0 ))
posts_dtm_2 = posts_dtm[row_sub,]
training7 <- LDA(posts_dtm_2, k = 7, control = list(seed = SEED))
training7@terms[1:10]
ncol(training@terms)
ncol(training7@terms)
nrow(training7@terms)
class(training7@terms)
size(training7@terms)
training7@documents
posts_dtm_2
posts_dtm
posts_corpus[1:5]
inspect(posts_corpus[1:5_]
inspect(posts_corpus[1:5])
inspect(posts_corpus[6:10])
dtm <- DocumentTermMatrix(posts_dtm, control = list(weighting =
function(x)
weightTf(x), removePunctuation = TRUE,
stopwords = TRUE))
dtm <- DocumentTermMatrix(posts_corpus, control = list(weighting =
function(x)
weightTf(x), removePunctuation = TRUE,
stopwords = TRUE))
dtm[10,]
inspect(dtm[10,])
inspect(dtm[10, 1:100])
inspect(dtm[10, 10000:10010])
row_sub = apply(dtm, 1, function(row) all(row !=0 ))
inspect(dtm[1, 30000:30010])
ncol(dtm)
inspect(dtm[1, 38000:38100])
inspect(dtm[1, 37000:37010])
inspect(dtm[1, 37500:37510])
inspect(dtm[1, 38500:38510])
inspect(dtm[1, 37600:37610])
inspect(dtm[1, 37620:37630])
inspect(dtm[1, 37650:37700])
inspect(dtm[1, 37750:37800])
inspect(dtm[1, 37800:37850])
inspect(dtm[1, "writer"])
inspect(dtm[1, "myself"])
inspect(dtm[1, "thanks"])
inspect(dtm[1, "been"])
inspect(dtm[1, "experience"])
inspect(dtm[1, "enriching"])
inspect(dtm[1, "experience,,,"])
data()
JSS_papers
posts = read.csv("~/work/code/courses/mooc/fsf-coursera/converted.csv")
typeof(posts)
class(posts)
posts[1:10]
posts[1:10, 1:3]
posts[1,]
posts_e <- posts[sapply(posts[, "description"],
+    Encoding) == "unknown",]
posts[1,]
posts[1, "post_text"]
posts[1:3, "post_text"]
posts[1:5, "post_text"]
help(sapply)
sapply(posts[1:10, "post_text"], Encoding)
sapply(posts[1:10, "post_text"], Encoding) == "unknown"
data("JSS_papers", package = "corpus.JSS.papers")
JSS_papers <- JSS_papers[sapply(JSS_papers[, "description"],
+    Encoding) == "unknown",]
JSS_papers <- JSS_papers[sapply(JSS_papers[, "description"],
Encoding) == "unknown",]
JSS_papers <- JSS_papers[sapply(JSS_papers[, "description"], Encoding) == "unknown",]
Encoding
help(Encoding)
Encoding('asdasd')
Encoding('Hello')
Encoding("Hello")
[ 1, 2, 3, 4 ]
([) 1, 2, 3, 4 )
( 1, 2, 3, 4 )
c(1, 2, 3, 4)
c(1, 2, 3, 4) == 1
posts <- posts[sapply(posts[, "description"], Encoding) == "unknown"]
posts <- posts[sapply(posts[, "description"], Encoding) == "unknown",]
posts <- posts[sapply(posts[, "post_text"], Encoding) == "unknown"]
posts <- posts[sapply(posts[, "post_text"], Encoding) == "unknown",]
class(posts[1, "post_text"])
help(factor)
typeof(posts[1, "post_text"])
posts[1, "post_text"]
posts[1:1, "post_text"]
posts[1:3, "post_text"]
posts(1:3, "post_text")
posts(1, "post_text")
posts[1, "post_text"]
str <- posts[1, "post_text"]
str[1]
JSS_papers[1, "description"]
class(JSS_papers[1, "description"])
typeof(JSS_papers[1, "description"])
JSS_papers[1, "description"]
class(JSS_papers)
class(posts)
posts[1, 1]
class(posts[1, 1])
class(posts[1, 3])
posts[1, 1]
posts[1, 3]
posts[1, 4]
posts[1, 5]
posts[1, 6]
posts[1, ]
posts[1,7]
posts <- posts[lapply(posts[, "post_text"], Encoding) == "unknown",]
help(lapply)
help(sapply)
posts_1 <- data.frame(lapply(posts, as.character), stringsAsFactors=FALSE);
posts_enc <- posts1[sapply(posts1[, "post_text"], Encoding) == "unknown",]
posts_enc <- posts_1[sapply(posts_1[, "post_text"], Encoding) == "unknown",]
posts <- posts_enc;
corpus <- Corpus(DataframeSource(posts[, "post_text"]));
library("tm")
corpus <- Corpus(DataframeSource(posts[, "post_text"]));
posts[1, "post_text"]
posts[1:5, "post_text"]
corpus <- Corpus(VectorSource(posts[, "post_text"]));
corpus <- Corpus(VectorSource(posts[, "post_text"]));
posts_dtm <- DocumentTermMatrix(corpus, control = list(stemming = TRUE, stopwords = TRUE, minWordLength = 3, removeNumbers = TRUE, removePunctuation = TRUE));
dim(posts_dtm)
summary(col_sums(JSS_dtm))
summary(col_sums(posts_dtm))
library("topicmodeling")
library("topicmodels", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
col_sums
??col_sums
library("slam", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
summary(col_sums(posts_dtm))
summary(col_sums(posts_dtm))
posts_dtm$v
dim(posts_dtm)
posts_dtm$dimnames
l
help(DocumentTermMatrix)
help(tapply)
term_tfidf <- tapply(posts_dtm$v/row_sums(posts_dtm)[posts_dtm$i], posts_dtm$j, mean) * log2(nDocs(posts_dtm)/col_sums(posts_dtm > 0));
summary(term_tfidf)
summary(col_sums(posts_dtm))
posts_dtm <- posts_dtm[, term_tfidf >= 0.1]
dim(posts_dtm)
summary(row_sums(posts_dtm))
posts_dtm <- posts_dtm[row_sums(posts_dtm) > 0,]
dim(posts_dtm)
summary(col_sums(JSS_dtm))
summary(col_sums(posts_dtm))
posts_dtm(posts_dtm > 2400)
posts_dtm[posts_dtm > 2400]
posts_model <- LDA(posts_dtm, k = k, method = "Gibbs",
control = list(seed = seed, burnin = 1000, thin = 100, iter = 1000));
k <- 10
seed <- 11121
posts_model <- LDA(posts_dtm, k = k, method = "Gibbs",
control = list(seed = seed, burnin = 1000, thin = 100, iter = 1000));
dtm <- DocumentTermMatrix(corpus, control = list(weighting =
function(x)
weightTf(x), removePunctuation = TRUE,
stopwords = TRUE))
dim(dtm)
dim(posts_dtm)
posts_model
posts_model@alpha
posts_model@loglikelihood
posterior(posts_model)$topics
help(posterior)
??posterior
help(topics)
topics(posts_model)
dim(posts_drm)
dim(posts_dtm)
topics(posts_model)[1:10]
topics(posts_model, 1)
topics(posts_model, 3)[1:10]
topics(posts_model, 3)
wordAssignMat <- as.matrix(posts_model@wordassignments)
wordAssignMat[1:10, 1:10]
wordAssignMat[1:10, 1000:1050]
summary(wordAssignMat)
help(terms)
??terms
help(topics)
dim(terms(posts_model, 2))
terms(posts_model, 2)
terms(posts_model, 10)
terms(posts_model, 15)
dim(topics(posts_model))
dim(topics(posts_model, 2))
dim(topics(posts_model, 10))
dim(topics(posts_model, 1))
dim(topics(posts_model, 2))
dim(topics(posts_model, 5))
dim(topics(posts_model, 5))[, 1:10]
topics(posts_model, 5)[, 1:10]
dim(topics(posts_model, 10))
dim(topics(posts_model, 11))
dim(topics(posts_model, 100))
SS_papers[, "identifier"])]
JSS_papers[, "identifier"])]
JSS_papers[, "identifier"]
topics(posts_model)
dim(topics(posts_model))
dim(topics(posts_model, 1))
dim(topics(posts_model, 2))
dim(posts)
summary(posts)
dim(unique(posts["post_author"]))
unique(posts["post_author"])[1:10]
unique(posts["post_author"])[1:10,]
posts["post_author" == "James McCarthy"]
dim(posts["post_author"] == "James McCarthy")
dim(posts)
subset(posts, post_author == "ames McCarthy")
subset(posts, post_author == "James McCarthy")
dim(subset(posts, post_author == "James McCarthy"))
help(tabulate)
dim(posterior(training)$terms)
dim(posterior(posts_model)$terms)
dim(posts)
dim(posts_dtm)
terms(posts_model, 15)
dim(posterior(training)$topics)
posterior(training)$topics
dim(posterior(posts_model)$topics)
posterior(training)$topics[1:5,]
posterior(posts_model)$topics[1:5,]
docTopicProbs <- posterior(posts_model)$topics
class(docTopicProbs)
which.max(docTopicProbs[,10])
help(which.max)
docTopicProbs(2539, 10)
docTopicProbs[2539, 10]
docTopicProbs[2536, 10]
summary(docTopicProbs[,10])
max(docTopicProbs[,10])
max(docTopicProbs[,10], 2)
max(docTopicProbs[,10], 0.1)
which.max(docTopicProbs[,10])
which.min(docTopicProbs[,10])
which.is.max(docTopicProbs[,10])
which.max(docTopicProbs[,10], 3)
order(docTopicProbs[,10])[1:5]
docTopicProbs[order(docTopicProbs[,10])[1:5], 10]
help(order)
docTopicProbs[order(docTopicProbs[,10], decreasing = TRUE)[1:5], 10]
posts[order(docTopicProbs[,10], decreasing = TRUE)[1:5], "post_text"]
getPostsForTopic
getPostsForTopic <- function(docTopicProbs, documents, topicNumber, numTopics) {
return corpus[order(docTopicProbs[, topicNumber], decreasing = TRUE)[1:numTopics]];
}
getPostsForTopic <- function(docTopicProbs, documents, topicNumber, numTopics) {
return corpus[order(docTopicProbs[, topicNumber], decreasing = TRUE)[1:numTopics]]
}
corpus[order(docTopicProbs[, 10], decreasing = TRUE)[1:5]]
corpus[order(docTopicProbs[, 10], decreasing = TRUE)[1:5]]
posts_text[order(docTopicProbs[,10], decreasing = TRUE)[1:5]]
posts_text <- posts[, "post_text"]
posts_text[order(docTopicProbs[,10], decreasing = TRUE)[1:5]]
getPostsForTopic <- function(docTopicProbs, documents, topicNumber, numTopics) {
return documents[order(docTopicProbs[, topicNumber], decreasing = TRUE)[1:numTopics]]
}
posts_text[order(docTopicProbs[, 10], decreasing = TRUE)[1:2]]
getDocumentsForTopic <- function(documents, docTopicProbs, topicNumber, numDocuments = 5) {
return documents[order(docTopicProbs[, topicNumber], decreasing = TRUE)[1:numDocuments]]
}
getDocumentsForTopic <- function(documents, docTopicProbs, topicNumber, numDocuments = 5) {
documents[order(docTopicProbs[, topicNumber], decreasing = TRUE)[1:numDocuments]]
}
getDocumentsForTopic(posts_text, docTopicProbs, 5, 2)
l
getDocumentsForTopic <- function(documents, docTopicProbs, topicNumber, numDocuments = 5) {
documents[order(docTopicProbs[, topicNumber], decreasing = TRUE)[1:numDocuments]]
}
getMostPopularTopicsForDocument <- function(model, documentNumber, numTopics) {
topics(model, numTopics)[, documentNumber]
}
getMostPopularTopicsForDocument(posts_model, 100, 4)
getMostPopularTopicsForDocument(posts_model, 101, 4)
getMostPopularTopicsForDocument(posts_model, 101, 7)
getMostPopularTopicsForDocument(posts_model, 101, 3)
getMostPopularTopicsForDocument(posts_model, 101, 3)
getMostPopularWordsForTopic <- function(model, topicNumber, numTerms = 10) {
terms(model, numTerms)[, topicNumber]
}
getMostPopularWordsForTopic(posts_model, 10, 5)
getMostPopularWordsForTopic(posts_model, 10, 10)
getMostPopularWordsForTopic(posts_model, 10, 15)
getMostPopularWordsForTopic(posts_model, 10, 20)
getMostPopularWordsForTopic(posts_model, 10, 100)
getMostPopularWordsForTopic(posts_model, 10, 20)
dim(docTopicProbs)
docTopicProbs[1, 5]
docTopicProbs[1, 1:5]
posts["post_author" == "James McCarthy"]
posts[which(posts$post_author == "James McCarthy")][1:5, "post_text"]
dim(posts[which(posts$post_author == "James McCarthy")])
dim(posts[which(posts$post_author == "James McCarthy"), "post_text"])
which(posts$post_author == "James McCarthy")
dim(subset(posts, post_author == "James McCarthy"))
dim(which(posts$post_author == "James McCarthy"))
size(which(posts$post_author == "James McCarthy"))
length(which(posts$post_author == "James McCarthy"))
which(posts$post_author == "James McCarthy")
posts[which(posts$post_author == "James McCarthy"), "post_text"]
docTopicProbs[which(posts$post_author == "James McCarthy")]
docTopicProbs[which(posts$post_author == "James McCarthy"),]
sum(docTopicProbs[which(posts$post_author == "James McCarthy"),])
docTopicProbs[which(posts$post_author == "James McCarthy"),]
class(docTopicProbs[which(posts$post_author == "James McCarthy"),])
typeof(docTopicProbs[which(posts$post_author == "James McCarthy"),])
col_sum(docTopicProbs[which(posts$post_author == "James McCarthy"),])
cosl_sum(docTopicProbs[which(posts$post_author == "James McCarthy"),])
cols_sum(docTopicProbs[which(posts$post_author == "James McCarthy"),])
colSums(docTopicProbs[which(posts$post_author == "James McCarthy"),])
order(colSums(docTopicProbs[which(posts$post_author == "James McCarthy"),]), decreasing = TRUE)
getTopTopicsForUser <- function(docTopicProbs, documents, user) {
order(colSums(docTopicProbs[which(posts$post_author == user),]), decreasing = TRUE)
}
getTopTopicsForUser(docTopicProbs, posts, "James McCarthy")
unique(posts$post_author)
unique(posts$post_author)[1:10]
getTopTopicsForUser(docTopicProbs, posts, "chirag sindhu")
getMostPopularWordsForTopic(docTopicProbs, 5)
getMostPopularWordsForTopic(posts_model, 5)
getMostPopularWordsForTopic(posts_model, 4)
getMostPopularWordsForTopic(posts_model, 7)
getTopTopicsForUser <- function(docTopicProbs, documents, user) {
order(colSums(docTopicProbs[which(posts$post_author == user),]), decreasing = TRUE)
}
savehistory("~/work/code/courses/mooc/rhistory_2013_11_18.Rhistory")
